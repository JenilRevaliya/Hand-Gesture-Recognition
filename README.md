Hand Gesture Recognition and UI Display ğŸ¤—ğŸ¯

â€¢ This is a real-time hand gesture recognition application built with Python, using MediaPipe for hand tracking and PyQt5 for a responsive graphical user interface. The program detects various hand gestures, displays real-time information, and provides audio feedback for recognised gestures.
â€¢ The project is designed to be modular and easy to expand, making it an excellent starting point for computer vision and human-computer interaction projects.


ğŸš€ Features

	â€¢	Real-time Hand Tracking: Uses your webcam to detect up to two hands with high accuracy. ğŸ¥
	â€¢	Gesture Recognition: Recognises several predefined hand gestures, including:
	    â—¦	Fist âœŠ
	    â—¦	Open Hand ğŸ‘‹
	    â—¦	Peace âœŒï¸
	    â—¦	Thumbs Up ğŸ‘
	    â—¦	Pointing ğŸ‘†
	    â—¦	Pinky ğŸ¤™
	    â—¦	Party ğŸ¤Ÿ
	â€¢	Directional Detection: Identifies if the hand is pointing Left ğŸ‘ˆ or Right ğŸ‘‰.
	â€¢	Audio Feedback: A voice announces the name of a gesture when it is recognized. ğŸ—£ï¸
	â€¢	Responsive GUI: Built with PyQt5, the application runs smoothly without freezing, thanks to multi-threading. ğŸ’»
	â€¢	Clean UI Overlays: Information like FPS, gesture name, and finger count is displayed directly on the video feed. ğŸ“Š


ğŸ› ï¸ Installation

This project requires a few key libraries. It's highly recommended to use a virtual environment to avoid conflicts with your system's Python installation. ğŸ“¦
1.	Clone the Repository (or save the code): Save the provided Python script as app.py on your computer.


2.	Open Terminal and Navigate to the Project Directory:
   
    cd /path/to/your/projectâ€¨


3.	Create and Activate a Virtual Environment: This step ensures all packages are installed locally for this project.

    python3.11 -m venv venv
    source venv/bin/activate

â€¨â€¨
4.	Install the Required Libraries: The following command installs all the necessary packages, including PyQt5 for the GUI and audio libraries for voice             feedback.

   pip install mediapipe==0.10.21 opencv-python numpy PyQt5 gtts pydub simpleaudio



ğŸƒ How to Run

After installation, simply run the Python script from your terminal with the virtual environment activated.

   python app.py


The application window will open, and your webcam feed will be displayed.
	â€¢	Show your palm to the camera. âœ‹
	â€¢	Try out different gestures like an Open Hand, Fist, or Peace sign. ğŸ¤˜
	â€¢	The application will display the detected gesture and provide a voice announcement. ğŸ‰
	â€¢	To exit, click the EXIT button or press q on your keyboard. ğŸšª


ğŸ“ˆ Future Aspects and Expansion

This program is specifically designed to be easily expanded. Here's how you can take it further:

	â€¢	Advanced Gesture Library: You can add more complex gestures and associate them with specific actions. The GestureRecognizer class is built for this purpose; you only need to define the new finger patterns. âœï¸
 
	â€¢	Machine Learning Integration: Instead of relying on hardcoded rules for finger patterns, you could train a custom machine learning model to recognise gestures. This would make the system more robust and adaptable to variations in hand shape and lighting. ğŸ¤–
	â€¢	User Profiles: Implement a feature to save custom gestures for different users. This would allow a user to train the system to recognise their unique hand movements. ğŸ‘¤
	â€¢	Kalman Filters: For even smoother tracking and less jitter, you could replace the current deque smoothing method with a Kalman filter. This advanced algorithm predicts the future position of a landmark based on its past movement, making it ideal for real-time tracking. Kalman Filter
